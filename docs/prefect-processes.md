# Creating prefect-based processes

Prefect-based processes are able to use all prefect features such as blocks, deployments, scheduling, etc.


## Defining a prefect process

Prefect pygeoapi processes need to derive from `pygeoapi_prefect.process.base.BasePrefectProcessor` and they need to
define two class variables:

- `process_flow` - This is a reference to the prefect flow function that is executed whenever pygeoapi receives a
  process execution request

  In order for a prefect flow to be usable as the `process_flow` of a pygeoapi process, there are some requirements
  that must be met:

  1. The flow definition must at least include the `persist_result=True` parameter;

  2. Flows must accept the following parameters:

      - `job_id: str` - The pygeoapi job id, as generated by its process manager

      - `result_storage_block: str` - the extended name (_i.e._ `<block-type-slug>/<block-name>`) of a prefect block that
        is to be used for storing whatever outputs are to be generated during execution

      - `process_description: ProcessDescription` - The details about the processor, as known by pygeoapi

      - `execution_request: ExecuteRequest` - Execution-related details about the current pygeoapi job to be used in the
        flow run

  3. Flows must store whatever results they produce using a prefect storage block

  4. Flows must return an instance of `pygeoapi.models.processes.JobStatusInfoInternal`


- `process_description` - This must be an instance of `pygeoapi.models.processes.ProcessDescription` and contains
  a description of the process, including its inputs as outputs. The only major requirement here is that the
  description's `id` property needs to match the name of the process, as specified in the pygeoapi configuration file


A full example:

```python
from prefect import flow, get_run_logger
from prefect.blocks.core import Block
from prefect.filesystems import LocalFileSystem
from pygeoapi.models import processes as schemas
from pygeoapi.process import exceptions
from pygeoapi_prefect.process.base import BasePrefectProcessor


# This is just a regular prefect flow, that respects pygeoapi's requirements, namely:
# - has persist_results=True
# - accepts the relevant input parameters (job_id, result_storage_block, process_description, execution_request)
# - stores outputs using prefect block
# - returns a status_info
@flow(persist_result=True)
def simple_flow(
        job_id: str,
        result_storage_block: str | None,
        process_description: schemas.ProcessDescription,
        execution_request: schemas.ExecuteRequest
) -> schemas.JobStatusInfoInternal:
    logger = get_run_logger()
    logger.debug("Starting execution...")
    # 1. retrieve inputs

    # some may be mandatory
    try:
        name = execution_request.inputs["name"].__root__
    except KeyError:
        raise exceptions.MissingJobParameterError("Cannot process without a name")
    else:
        # others may be optional
        msg = execution_request.inputs.get("message")
        message = msg.__root__ if msg is not None else ""

        # 2. determine where results will be stored
        if result_storage_block is not None:
            file_system = Block.load(result_storage_block)
        else:
            file_system = LocalFileSystem()

        # 3. Perform the actual generation of outputs
        result_value = f"Hello {name}! {message}".strip()

        # 4. Store the generated outputs using a prefect block
        result_path = f"{job_id}/output-result.txt"
        file_system.write_path(result_path, result_value.encode("utf-8"))

        # 5. Return a status info object
        return schemas.JobStatusInfoInternal(
            jobID=job_id,
            processID=process_description.id,
            status=schemas.JobStatus.successful,
            generated_outputs={
                "result": schemas.OutputExecutionResultInternal(
                    location=f"{file_system.basepath}/{result_path}",
                    media_type=(
                        process_description.outputs["result"].schema_.content_media_type
                    ),
                )
            },
        )


# Our custom pygeoapi processor, with its two mandatory properties (process_flow, and process_description)
class SimpleFlowProcessor(BasePrefectProcessor):
    process_flow = simple_flow
    process_description = schemas.ProcessDescription(
        id="simple-flow",  # id MUST match key given in pygeoapi config
        version="0.0.1",
        title="Simple flow Processor",
        jobControlOptions=[
            schemas.ProcessJobControlOption.SYNC_EXECUTE,
            schemas.ProcessJobControlOption.ASYNC_EXECUTE
        ],
        inputs={
            "name": schemas.ProcessInput(
                title="Name",
                schema=schemas.ProcessIOSchema(type=schemas.ProcessIOType.STRING)
            ),
            "message": schemas.ProcessInput(
                title="Message",
                schema=schemas.ProcessIOSchema(type=schemas.ProcessIOType.STRING),
                minOccurs=0
            ),
        },
        outputs={
            "result": schemas.ProcessOutput(
                schema=schemas.ProcessIOSchema(type=schemas.ProcessIOType.STRING, contentMediaType="text/plain")
            )
        },
    )
```


## Deploying a process

Prefect-based processes can be deployed by prefect onto appropriate blocks, thus enabling their future usage on
non-local nodes.

- run the CLI command


## Integrate process into pygeoapi

Once a custom process has been defined, it can be integrated

- modify pygeoapi configuration file
- specify deployment options
- specify result storage options




## Execute process

- Examples:
  - sync execution without deployment

    ```shell
    http localhost:5000/processes/simple-flow/execution \
        inputs:='{"name": "John Doe"}'
    ```
  - async execution without deployment (currently not supported)

  - sync execution with deployment (warn about not using a reloader web server)

    ```shell
    http localhost:5000/processes/simple-flow/execution \
        inputs:='{"name": "John Doe"}'
    ```

  - async execution with deployment

    ```shell
    http localhost:5000/processes/simple-flow/execution \
        Prefer:respond-async \
        inputs:='{"name": "John Doe"}' \
    ```

  - async execution with deployment and using a response of type `document`

    ```shell
    http localhost:5000/processes/simple-flow/execution \
        Prefer:respond-async \
        response=document \
        inputs:='{"name": "John Doe"}'
    ```

  - async execution with deployment and using a response of type `document` with result being requested by reference

    ```shell
    http localhost:5000/processes/simple-flow/execution \
        Prefer:respond-async \
        response=document \
        inputs:='{"name": "John Doe"}'
        outputs:='{"result": {"transmissionMode": "reference"}}'
    ```


### Retrieve execution results

- with a storage block
- without it
